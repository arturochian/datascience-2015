# Summary
- It's been a great journey!
- We've learned a ton of different techniques and gained a pretty broad exposure to different areas of datascience.

# Next steps
To keep on progressing, here are the three areas that I would recommend:

1. Sharpen your toolkit
2. Learn the models more deeply
3. Practice a ton


# Sharpen Your Toolkit
## Python
The better your Python skills are, the more easily you'll be able to navigate, use and where necessary customize the different libraries available to you. If none exists, you could even develop one. To this end,

1. Do as many Euler problems as possible
2. Build end-to-end apps (either Django or Flask), as this increase your awareness of how different software components can work together.
3. Read some source code, whether it's scikitlearn or something else, so you get a sense of how high-quality professional code looks like.

## R
In industry, most datascientists R and RStudio for rapid exploratory analysis. It's not very difficult to learn and its main advantage is that there are so many statistical packages written for R.

[Here](http://tryr.codeschool.com/) is an effective, interactive tutorial of the language.

Once you've gotten the basics down, I would recommend going through the [R Code Labs](http://www-bcf.usc.edu/~gareth/ISL/) of Introduction to Statistical Learning.

## Spark/Hadoop
As you noticed from your final project, it can take a ton of time to run analyses on your local machine serially. 

Learn about parallelizing these tasks via MapReduce. Going through the [Spark](https://spark.apache.org/) tutorials is a good place to start.

## Visualization
If you can do powerful analyses and tell incredibly compelling visual stories with the data, you will be unstoppable.

It's worth it to get good at [D3](http://d3js.org/) and improve your `matplotlib` skills.


# Learn the models more deeply
I would be willing to bet that we went more in depth on the math behind the models than most datascience classes. Now that you have had a chance to practice some of the techniques in your final project, you would benefit from understanding even more granularly the mechanics of the models you employ, because that will give you a better handle of when to use them and how to tune them for maximum effect.


## The Requisite Math
To get to the next level of datascience, you should have a strong undergraduate understanding of the following:

1. Probability - check out this [phenomenal book](http://www.amazon.com/First-Course-Probability-9th-Edition/dp/032179477X) by Sheldon Ross.
2. Statistics
3. Linear Algebra - great [book](http://www.amazon.com/Linear-Algebra-Its-Applications-Edition/dp/0030105676) by Gilbert Strang. He has some online lecture videos as well.

Once you feel strong with the math, move on to [The Elements of Statistical Learning](http://statweb.stanford.edu/~tibs/ElemStatLearn/) - this is THE BIBLE of datascience. You can learn from it or just use it as reference.


# Practice a ton
Nothing will hone your skills like tackling datasets with a concrete objective in mind.

To improve on the datawrangling side, work with real, unmanicured public datasets or scrape them yourself.

[Kaggle](http://kaggle.com/competitions) is a great source of semi-manicured data. Depending on the specific Kaggle competition, you'll have to do some if not a ton of data clean up, aggregation, etc.

If you want to scrape, learn [BeautifulSoup](https://beautiful-soup-4.readthedocs.org/en/latest/) and [Scrapy](http://scrapy.org/). The former is for simple scraping tasks while the latter is a powerful customizable framework for complex, deep scraping and crawling.

Tips:
- Do Kaggle competitions
- Learn scraping
- Hack with others better than you
- Push yourself to get better at harder techniques like neural networks


# Closing
- Let's keep in touch - my email is suneel@suneelchakravorty.com
- Come to dat-alum meetups/happy hours - Daniel emailed out some info about this
- We'll have a reunion happy hour in the summer

# Bon voyage!
